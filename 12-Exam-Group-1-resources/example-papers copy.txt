# Deep Learning
## Scientific Papers: Some Ideas

Image Classification
====================
1. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Tan & Le, 2019: https://arxiv.org/abs/1905.11946v5
2. MobileNetV2: Inverted Residuals and Linear Bottlenecks, Sandler et al., 2018 (CVPR): https://arxiv.org/abs/1704.04861v1
3. Densely Connected Convolutional Networks, Huang et al., 2017 (CVPR): https://arxiv.org/abs/1608.06993v5
4. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, Dosovitskiy et al., 2021 (ICLR): https://arxiv.org/abs/2010.11929v2
5. A Simple Framework for Contrastive Learning of Visual Representations, Chen et al., 2020 (ICML): https://arxiv.org/abs/2002.05709

Object Detection (2D / 3D)
==========================
1. VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection, Zhou & Tuzel, 2018 (CVPR): https://arxiv.org/abs/1711.06396v1
2. High-Resolution Representations for Labeling Pixels and Regions, Sun et al., 2019: https://arxiv.org/abs/1904.04514v1
3. PointPainting: Sequential Fusion for 3D Object Detection, Vora et al., 2020 (CVPR): https://arxiv.org/abs/1911.10150v2
4. Stereo R-CNN based 3D Object Detection for Autonomous Driving, Li et al., 2019 (CVPR): https://arxiv.org/abs/1902.09738v2
5. Objects as Points, Zhou et al., 2019: https://arxiv.org/abs/1904.07850v2

Semantic / Instance Segmentation
================================
1. FCOS: Fully Convolutional One-Stage Object Detection, Tian et al., 2019
2. Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation, Chen et al., 2018 (ECCV): https://arxiv.org/abs/1802.02611v3
3. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows, Liu et al., 2021 (ICCV): https://arxiv.org/abs/2103.14030
4. Dual Attention Network for Scene Segmentation, Fu et al., 2019 (CVPR): https://arxiv.org/abs/1809.02983v4
5. Point Transformer, Zhao et al., 2021 (ICCV): https://arxiv.org/abs/2012.09164v2
6. Fast Online Object Tracking and Segmentation: A Unifying Approach, Wang et al., 2019 (CVPR): https://arxiv.org/abs/1812.05050v2
7. Semi-Supervised Semantic Segmentation with Cross-Consistency Training, Ouali et al., 2020 (CVPR): https://arxiv.org/abs/2003.09005v3
8. Robust Object Detection via Instance-Level Temporal Cycle Confusion, Wang et al., 2021 (ICCV): https://arxiv.org/abs/2104.08381v2

Image GANs
==========
1. A Style-Based Generator Architecture for Generative Adversarial Networks, Karras et al., 2019 (CVPR): https://arxiv.org/abs/1812.04948v3
2. Analyzing and Improving the Image Quality of StyleGAN, Karras et al., 2020 (CVPR): https://arxiv.org/abs/1912.04958v2
3. Training Generative Adversarial Networks with Limited Data, Karras et al, 2020 (NeurIPS): https://arxiv.org/abs/2006.06676v2
4. Alias-Free Generative Adversarial Networks, Karras et al., 2021: https://arxiv.org/abs/2106.12423
5. Semantic Image Synthesis with Spatially-Adaptive Normalization, Park et al., 2019 (CVPR): https://arxiv.org/abs/1903.07291v2
6. Few-Shot Unsupervised Image-to-Image Translation, Liu et al., 2019 (ICCV): https://arxiv.org/abs/1905.01723v2
7. Everybody Dance Now, Chan et al., 2019 (ICCV): https://arxiv.org/abs/1808.07371v2

Model Explainability
====================
1. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Selvaraju et al., 2016: https://arxiv.org/abs/1610.02391v4
2. Explaining Local, Global, And Higher-Order Interactions In Deep Learning, Lerman et al., 2021 (CVPR): https://arxiv.org/abs/2006.08601v4
3. Convolutional Neural Network Interpretability with General Pattern Theory, Tjoa & Cuntai, 2021: https://arxiv.org/abs/2102.04247v1
4. Learning to Structure an Image with Few Colors, Hou et al., 2020 (CVPR): https://arxiv.org/abs/2003.07848v2
5. Visual Interpretability for Deep Learning: a Survey, Zhang & Zhu, 2018: https://arxiv.org/abs/1802.00614v2
6. Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models, Heskes et al., 2020 (NeurIPS): https://arxiv.org/abs/2011.01625v1

Language Models
===============
1. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Devlin et al., 2019 (NAACL): https://arxiv.org/abs/1810.04805v2
2. RoBERTa: A Robustly Optimized BERT Pretraining Approach, Liu et al., 2019: https://arxiv.org/abs/1907.11692v1
3. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter, Sanh et al., 2019 (NeurIPS): https://arxiv.org/abs/1910.01108v4
4. Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context, Dai et al., 2019 (ACL): https://arxiv.org/abs/1901.02860v3
5. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension, Lewis et al., 2020 (ACL)
6. Universal Language Model Fine-tuning for Text Classification, Howard & Ruder, 2018 (ACL): https://arxiv.org/abs/1801.06146v5
7. Deep contextualized word representations, Peters et al., 2018 (NAACL): https://arxiv.org/abs/1802.05365v2
8. Domain-Adversarial Training of Neural Networks, Ganin et al., 2015: https://arxiv.org/abs/1505.07818v4

Collaborative Filtering
=======================
1. Variational Autoencoders for Collaborative Filtering, Liang et al., 2019: https://arxiv.org/abs/1802.05814v1
2. Neural Graph Collaborative Filtering, Wang et al., 2019: https://arxiv.org/abs/1905.08108v2
3. Deep Learning Recommendation Model for Personalization and Recommendation Systems, Naumov et al., 2019: https://arxiv.org/abs/1906.00091v1
4. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer, Sun et al., 2019